{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FE545 - Homework #4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author**: Sid Bhatia\n",
    "\n",
    "**Date**: April 6th, 2023\n",
    "\n",
    "**Pledge**: I pledge my honor that I have abided by the Stevens Honor System.\n",
    "\n",
    "**Professor**: Steve Yang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pricing a derivative security entails calculating the *expected discounted value* of its *payoff*. This reduces, in principle, to a problem of numerical integration; but in practice this calculation is often difficult for high-dimensional pricing problems. \n",
    "\n",
    "**Broadie** and **Glasserman** (1997)  proposed the method of the simulated tree to price American options, which can derive the upper and lower bounds for American options. This combination makes it possible to measure and control errors as the computational effort increases. \n",
    "\n",
    "The main drawback of the random tree method is that its computational requirements grow exponentially in the number of exercise dates $m$, so the method is applicable only when $m$ is small. Nevertheless, for problems with small $m$, it is very effective, and it also serves to illustrate a theme of managing sources of high and low bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### High Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As its name suggests, the random tree method is based on simulating a tree of paths of the underlying **Markov Chain** $X_0, X_1, \\dots, X_m$. Fix a branching parameter $b \\geq 2$. From the initial state $X_0$, simulate $b$ independent successor states  $X_1^1, \\dots, X_1^B$ all having the **law** of $X_1$. For each $X_1^i$, simulate $b$ independent successors $X_1^{i1}, \\dots X_1^{ib}$ from the **conditional law** of $X_2$ given $X_1 = X_1^i$. From each $X_2^{i_1 i_2}$, generate $b$ successors $X_3^{i_1 i_2 1}, \\dots X_3^{i_1 i_2 b}$, and so on. We denote a *generic node* in the tree at time step $i$ by $X_i^{j_1 j_2 \\dots j_i}$. The superscript indicates that this node is reached by following the $j$-th branch out of $X_0$, the $j_2$-th branch out of the next node, and so on. \n",
    "\n",
    "Although it is not essential that the branching parameter remain fixed across time steps, this is a convenient simplification in discussing the method. From the random tree method we define high and low estimators at each node by backward induction.\n",
    "\n",
    "We use **formulation 2**. Thus, $\\hat{h}_i$ is the discounted payoff function at the $i$-th exercise date, and the discounted option value satisfies $\\hat{V}_m = \\hat{h}_m$,\n",
    "\n",
    "$$\n",
    "\\tilde{V}_i(x) = \\max{\\left(\\tilde{h}_i(x), \\mathbb{E}^Q[\\tilde{V}_{i+1}(X_{i+1}) \\mid X_i = x]\\right)}, \\; i = 1, \\dots, m - 1 \\tag{3}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write $\\hat{V}_i^{j_i \\dots j_i}$ for the **value of the high estimator** at node $X_i^{j_i \\dots j_i}$. At the terminal nodes, we set\n",
    "\n",
    "$$\n",
    "\\hat{V}_i^{j_1 \\dots j_m} h_m (X_m^{j_1 \\dots j_m}). \\tag{4}\n",
    "$$\n",
    "\n",
    "Working backward, we then set\n",
    "\n",
    "$$\n",
    "\\hat{V}_i^{j_1 \\dots j_i} = \\max{\\left( h_i (X_i^{j_1 \\dots j_i}), \\; \\frac{1}{b} \\sum_{j=1}^b \\hat{v}_{i+1}^{j_1 \\dots j_i j}\\right)}. \\tag{5}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Formulation 5** is based on successor nodes, so the estimator is unfairly peeking into the future in making its decision. To remove this source of bias, we need to separate the exercise decision from the value received upon continuation. A new estimator can be defined as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At all terminal nodes, set the estimator equal to the payoff at that node:\n",
    "\n",
    "$$\n",
    "\\hat{v}_m^{j_1 \\dots j_m} = h_m(X_m^{j_1 \\dots j_m}) \\tag{6}.\n",
    "$$\n",
    "\n",
    "At node $j_1, j_2, \\dots j_i$ at time step $i$, and for each $k = 1, \\dots, b$, set\n",
    "\n",
    "$$\n",
    "\\hat{v}_{ik}^{j_1 j_2 \\dots j_i} = \\begin{cases}\n",
    "\n",
    "h_i (X_i^{j_1 j_2 \\dots j_i}) & \\; \\text{if} \\; \\frac{1}{b} \\sum_{j = 1}^b \\hat{v}_{i + 1}^{j_1 j_2 \\dots j_i j} \\leq h_i (X_i^{j_1 j_2 \\dots j_i}); \\tag{7} \\\\\n",
    "\n",
    "\\hat{v}_{i + 1}^{j_1 j_2 \\dots j_i k} & \\; \\text{otherwise}\n",
    "\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Then set\n",
    "\n",
    "$$\n",
    "\\hat{v}_i^{j_1 \\dots j_i} = \\frac{1}{b} \\sum_{k=1}^b \\hat{v}_{i,k}^{j_1 \\dots j_i} \\tag{8}\n",
    "$$\n",
    "\n",
    "Working backward, we then set\n",
    "\n",
    "$$\n",
    "\\hat{V}_i^{j_1 \\dots j_i} = \\max{\\left( h_i(X_i^{j_1 \\dots j_1}), \\frac{1}{b} \\sum_{k=1}^b \\hat{V}_{i,k}^{j_1 \\dots j_i})\\right) } \\tag{9}\n",
    "$$\n",
    "\n",
    "The high estimator of the option price at the current time and state is $\\hat{v}_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, the high estimator is simply the result of applying **ordinary dynamic programming** to the *random tree*, assigning equal weight to each branch. Its calculation is illustrated in Figure 1 with $h_i(x) = (x - 100)_+$.\n",
    "\n",
    "A simple induction argument demonstrates that the high estimator is **indeed biased high** at every node, in the sense that\n",
    "\n",
    "$$\n",
    "\\mathbf{E}^Q[\\hat{V}_i^{j_1 \\dots j_i} \\mid X_i^{j_1 \\dots j_i}] = \\mathbf{E}[V_i^{j_i \\dots j_i}] \\tag{10}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img src=\"./fe545-hw4-figures/fe545-hw4-figure0.png\" alt=\"Trinomial Tree\" style=\"width: 30%; height: auto; display: block; margin-left: auto; margin-right: auto;\">\n",
    "    <figcaption style=\"text-align: center; font-size: larger; margin-top: 10px\">Figure 1: High Estimator K = 100</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The low estimator is defined as follows. At all terminal nodes, set the estimator equal to the payoff at that node:\n",
    "\n",
    "$$\n",
    "\\hat{v}_m^{j_1 j_2 \\dots j_m} = h_m (X_m^{j_1 j_2 \\dots j_m}) \\tag{11}\n",
    "$$\n",
    "\n",
    "At each node $j_1, j_2, \\dots, j_i$ at time step $i$, and for each $k = 1, \\dots b$, set\n",
    "\n",
    "$$\n",
    "\\hat{v}_{ik}^{j_1 j_2 \\dots j_i} = \\begin{cases}\n",
    "\n",
    "h_i (X_i^{j_1 j_2 \\dots j_i}) & \\; \\text{if} \\; \\frac{1}{b - 1} \\sum_{j=1; j \\neq k}^b \\hat{v}_{i+1}^{j_1 j_2 \\dots j_i j} \\leq h_i(X_i^{j_1 j_2 \\dots j_i}); \\tag{12}\n",
    "\n",
    "\\\\\n",
    "\n",
    "\\hat{v}_{i+1}^{j_1 j_2 \\dots j_i k} & \\; \\text{otherwise}\n",
    "\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "We then set\n",
    "\n",
    "$$\n",
    "\\hat{v}_i^{j_1 j_2 \\dots j_i} = \\frac{1}{b} \\sum_{k=1}^b \\hat{v}_{ik}^{j_1 j_2 \\dots j_i}. \\tag{13}\n",
    "$$\n",
    "\n",
    "The low estimator of the option price at the current time and state is $\\hat{v}_o$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume a random tree for pricing American call option is given in Figure 1. Please use the random tree in Figure 1 to calculate the high and low estimate of the American call option price with a **strike price $K = 50$**. Please show your steps for both the high estimator and low estimator.\n",
    "\n",
    "Note: You do not need to write C++ program to get the price, but rather manually calculating the estimators following the algorithms introduced in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 6.120045122283379, 20.699122904025828]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def compute_terminal_nodes(S0, K, r, sigma, T, n):\n",
    "    # Time delta per step\n",
    "    dt = T / n\n",
    "    # Compute up and down factors\n",
    "    u = math.exp(sigma * math.sqrt(dt))\n",
    "    d = 1 / u\n",
    "    # Compute risk-neutral probability\n",
    "    p = (math.exp(r * dt) - d) / (u - d)\n",
    "    \n",
    "    # Initialize terminal nodes list\n",
    "    terminal_nodes = []\n",
    "    \n",
    "    # Calculate terminal nodes using the binomial model formula\n",
    "    for i in range(n+1):\n",
    "        # The stock price at the ith terminal node\n",
    "        ST = S0 * (u ** i) * (d ** (n - i))\n",
    "        # Payoff of a call option at the ith terminal node\n",
    "        payoff = max(ST - K, 0)\n",
    "        terminal_nodes.append(payoff)\n",
    "    \n",
    "    return terminal_nodes\n",
    "\n",
    "# Test parameters\n",
    "S0 = 50  # Current stock price\n",
    "K = 50    # Strike price\n",
    "r = 0.05  # Risk-free interest rate\n",
    "sigma = 0.2  # Volatility\n",
    "T = 1     # Time to expiration in years\n",
    "n = 3     # Number of time steps\n",
    "\n",
    "# Compute terminal nodes\n",
    "terminal_nodes = compute_terminal_nodes(S0, K, r, sigma, T, n)\n",
    "terminal_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19.689614767666036, 28.02434217801937)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the value at a non-terminal node\n",
    "def calc_node_value(i, path, terminal_payoffs, n, r, dt, is_high_estimator=True):\n",
    "    if i == n:\n",
    "        return terminal_payoffs[len(path)]\n",
    "    \n",
    "    # Discount factor for one period\n",
    "    discount_factor = math.exp(-r * dt)\n",
    "    \n",
    "    successors = [calc_node_value(i + 1, path + (j,), terminal_payoffs, n, r, dt, is_high_estimator) for j in range(2)]\n",
    "    h_i = max(S0 * (path.count(1) - path.count(0)) - K, 0)\n",
    "\n",
    "    if is_high_estimator:\n",
    "        # High estimator does not need discounting as we are taking expectations\n",
    "        return max(h_i, sum(successors) / 2)\n",
    "    else:  # Low estimator\n",
    "        # Low estimator should be discounted back one period\n",
    "        discounted_successors = [v * discount_factor for v in successors]\n",
    "        continuation_value = sum(discounted_successors) - max(discounted_successors)\n",
    "        continuation_value /= (len(successors) - 1)\n",
    "        return max(h_i, continuation_value)\n",
    "    \n",
    "# Calculate high estimator\n",
    "high_estimator = calc_node_value(0, tuple(), terminal_nodes, n, r, T/n, True)\n",
    "\n",
    "# Calculate low estimator\n",
    "low_estimator = calc_node_value(0, tuple(), terminal_nodes, n, r, T/n, False)\n",
    "\n",
    "(low_estimator, high_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Black-Scholes formula is sufficiently complicated that there is no analytic inverse function, and therefore this inversion must be carried out numerically. Our objective is to use Newton-Ralphson method and the programming techniques to design a solver in a reusable fashion.\n",
    "\n",
    "When we have a well-behaved function with an analytic derivative, then Newton-Ralphson can be used to find inverse values of the Black-Scholes formula. The idea of Newton-Raphson is that we pretend the function is linear and look for the solution where the linear function predicts it to be. Thus, we take a standing point $x_0$, and approximate $f$ by\n",
    "\n",
    "$$\n",
    "g_0(x) = f(x_0) + f(x-x_0)f'(x_0) \\cdot \\epsilon \\tag{14}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have that $g_0(x) = 0$ iff\n",
    "\n",
    "$$\n",
    "x = \\frac{y - f(x_0)}{f'(x_0)} + x_0 \\tag{15}\n",
    "$$\n",
    "\n",
    "We therefore take this value as our new guess $x_1$. We repeat until we find that $f(x_n)$ is within $\\epsilon$ of $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, you will use a **pointer to a member function** which is similar in syntax and idea to a function pointer, but it is restricted to methods of a single class. The difference in syntax is that the class name with a :: must be attached to the * when it is declared. \n",
    "\n",
    "Thus, to declare function pointers called $\\texttt{Value}$ and $\\texttt{Derivative}$ which must point to methods of the class $T$, we have $\\texttt{double (T::*Derivative)(double) double}$ and $\\texttt{double (T::*Value) (double) double}$. The function $\\texttt{Value(Derivative)}$  is a const member function which takes in a double as an argument and outputs a double as return value. If we have an object of class $T$ called $\\texttt{TheObject}$ and $y$ is a double, then the function pointed to can be invoked by either $\\texttt{The Object.*Value(y)}$ or $\\texttt{TheObject.*Derivative(y)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the classes introduced in Lecture 09 and finish the main.cpp file for European Call Option with the following parameters:\n",
    "- $T = 1$\n",
    "- $S_0 = 50$\n",
    "- $K = 50$\n",
    "- $r = 0.05$\n",
    "- $q = 0.08$ (Dividend)\n",
    "- $P = 4.23$ (Option Price)\n",
    "- $\\sigma_g = 0.23$ (Vol Estimate)\n",
    "- $\\text{Tolerance} = 0.0001$\n",
    "\n",
    "Use the $\\texttt{NewtonRalphso}$ class from the sample as the starting point and find implied volatility for the given option price of 4.23."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```cpp\n",
    "// main.cpp\n",
    "\n",
    "#include <iostream>\n",
    "#include \"BSCallClass.h\"\n",
    "#include \"BlackScholesFormulas.h\"\n",
    "#include \"NewtonRaphso.h\"\n",
    "#include \"BSCallTwo.h\"\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "int main()\n",
    "{\n",
    "    double Expiry = 1.0;\n",
    "    double Strike = 50.0;\n",
    "    double Spot = 50.0;\n",
    "    double r = 0.05;\n",
    "    double d = 0.08; // This is the continuous dividend yield\n",
    "    double Price = 4.23;\n",
    "    \n",
    "    double start; // This will be the starting guess for the implied volatility\n",
    "    cout << \"Enter start volatility guess: \";\n",
    "    cin >> start;\n",
    "    \n",
    "    double tolerance;\n",
    "    cout << \"Enter Tolerance for Newton-Raphson: \";\n",
    "    cin >> tolerance;\n",
    "    \n",
    "    // Create function object for a vanilla call with all given parameters\n",
    "    BSCallTwo theCall(r, d, Expiry, Spot, Strike);\n",
    "    \n",
    "    // Use Newton-Raphson method to find the implied volatility\n",
    "    double vol = NewtonRaphson<BSCallTwo, &BSCallTwo::Price, &BSCallTwo::Vega>(Price, start, tolerance, theCall);\n",
    "\n",
    "    cout << \"\\nUsing Newton-Raphson method:\\n\";\n",
    "    cout << \"Implied vol is: \" << vol << endl;\n",
    "    \n",
    "    // Check the price using BlackScholesCall with the implied vol\n",
    "    double PriceTwo = BlackScholesCall(Spot, Strike, r, d, vol, Expiry);\n",
    "    \n",
    "    cout << \"Option price by implied volatility is: \" << PriceTwo << endl;\n",
    "    \n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```cpp\n",
    "Enter start volatility guess: 0.23\n",
    "Enter Tolerance for Newton-Raphson: 0.0001\n",
    "\n",
    "Using Newton-Raphson method:\n",
    "Implied vol is: 0.262937\n",
    "Option price by implied volatility is: 4.23005\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
